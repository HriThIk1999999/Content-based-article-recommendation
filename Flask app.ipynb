{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1hMVST8JWqA"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import os\n",
        "from flask import Flask, request, jsonify, render_template\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "from langchain.vectorstores import FAISS\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the OpenAI API key from environment variables\n",
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "# Load saved embeddings (assuming 'embeddings.pkl' contains 'documents' and 'embeddings')\n",
        "with open('C:\\Users\\hrith\\Desktop\\content_last\\document_embeddings_index.pkl', 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "\n",
        "documents = data['documents']\n",
        "embeddings = data['embeddings']\n",
        "\n",
        "# Initialize SentenceTransformer for embeddings (we assume embeddings are precomputed)\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Initialize FAISS vector store for efficient search\n",
        "vectorstore = FAISS.from_documents(documents, embedding_model)\n",
        "\n",
        "# Initialize Langchain with OpenAI LLM (using the API key)\n",
        "llm = OpenAI(api_key=api_key, model=\"text-davinci-003\")\n",
        "\n",
        "# Initialize the Langchain agent for answering queries\n",
        "agent = initialize_agent([llm], agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/recommend', methods=['POST'])\n",
        "def recommend_articles():\n",
        "    \"\"\"Recommend articles based on the content of the query.\"\"\"\n",
        "    query = request.json.get('query')\n",
        "\n",
        "    # Perform similarity search using FAISS\n",
        "    results = vectorstore.similarity_search(query, k=5)  # Top 5 most similar articles\n",
        "\n",
        "    recommended_articles = [result['document'] for result in results]\n",
        "\n",
        "    return jsonify({'recommendations': recommended_articles})\n",
        "\n",
        "@app.route('/query', methods=['POST'])\n",
        "def answer_query():\n",
        "    \"\"\"Answer user queries using the LLM (OpenAI model).\"\"\"\n",
        "    query = request.json.get('query')\n",
        "\n",
        "    # Use Langchain agent to answer the query\n",
        "    response = agent.run(query)\n",
        "\n",
        "    return jsonify({'answer': response})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ]
    }
  ]
}